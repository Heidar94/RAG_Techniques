{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4690030a",
   "metadata": {},
   "source": [
    "# Simple RAG (Retrieval-Augmented Generation) System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96a86c1",
   "metadata": {},
   "source": [
    "## Descripción general\n",
    "\n",
    "Este código implementa un sistema básico de Generación Aumentada por Recuperación (RAG) para procesar y consultar documentos PDF. El sistema codifica el contenido del documento en un almacén vectorial, que luego puede ser consultado para recuperar información relevante.\n",
    "\n",
    "**Componentes Clave**\n",
    "\n",
    "1. Procesamiento y extracción de texto de PDF\n",
    "2. Fragmentación del texto para un procesamiento manejable\n",
    "3. Creación de almacén vectorial utilizando FAISS y embeddings de OpenAI\n",
    "4. Configuración del recuperador para consultar los documentos procesados\n",
    "5. Evaluación del sistema RAG\n",
    "\n",
    "## Detalles del Método\n",
    "\n",
    "**Preprocesamiento del Documento**\n",
    "\n",
    "El PDF se carga utilizando PyPDFLoader.\n",
    "El texto se divide en fragmentos utilizando RecursiveCharacterTextSplitter con un tamaño y superposición especificados.\n",
    "\n",
    "**Limpieza del Texto**\n",
    "\n",
    "Se aplica una función personalizada `replace_t_with_space` para limpiar los fragmentos de texto. Esto probablemente aborda problemas específicos de formato en el PDF.\n",
    "\n",
    "**Creación del Almacén Vectorial**\n",
    "\n",
    "Se utilizan embeddings de OpenAI para crear representaciones vectoriales de los fragmentos de texto.\n",
    "Se crea un almacén vectorial FAISS a partir de estos embeddings para una búsqueda de similitud eficiente.\n",
    "\n",
    "**Configuración del Recuperador**\n",
    "\n",
    "Se configura un recuperador para obtener los 2 fragmentos más relevantes para una consulta dada.\n",
    "\n",
    "**Función de Codificación**\n",
    "\n",
    "La función `encode_pdf` encapsula todo el proceso de carga, fragmentación, limpieza y codificación del PDF en un almacén vectorial.\n",
    "\n",
    "**Características Clave**\n",
    "\n",
    "1. Diseño Modular: El proceso de codificación está encapsulado en una sola función para facilitar su reutilización.\n",
    "2. Fragmentación Configurable: Permite ajustar el tamaño y la superposición de los fragmentos.\n",
    "3. Recuperación Eficiente: Utiliza FAISS para una búsqueda de similitud rápida.\n",
    "4. Evaluación: Incluye una función para evaluar el rendimiento del sistema RAG.\n",
    "\n",
    "**Ejemplo de Uso**\n",
    "\n",
    "El código incluye una consulta de prueba: \"¿Cuál es la principal causa del cambio climático?\". Esto demuestra cómo utilizar el recuperador para obtener contexto relevante del documento procesado.\n",
    "\n",
    "**Evaluación**\n",
    "\n",
    "El sistema incluye una función `evaluate_rag` para evaluar el rendimiento del recuperador, aunque las métricas específicas utilizadas no se detallan en el código proporcionado.\n",
    "\n",
    "**Beneficios de este Enfoque**\n",
    "\n",
    "1. Escalabilidad: Puede manejar documentos grandes procesándolos en fragmentos.\n",
    "2. Flexibilidad: Fácil de ajustar parámetros como el tamaño del fragmento y el número de resultados recuperados.\n",
    "3. Eficiencia: Utiliza FAISS para una búsqueda de similitud rápida en espacios de alta dimensión.\n",
    "4. Integración con NLP Avanzado: Utiliza embeddings de OpenAI para una representación de texto de vanguardia.\n",
    "\n",
    "**Conclusión**\n",
    "\n",
    "Este simple sistema RAG proporciona una base sólida para construir sistemas más complejos de recuperación de información y respuesta a preguntas. Al codificar el contenido del documento en un almacén vectorial, permite la recuperación eficiente de información relevante en respuesta a consultas. Este enfoque es particularmente útil para aplicaciones que requieren acceso rápido a información específica dentro de documentos o colecciones de documentos grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c139c8e8",
   "metadata": {},
   "source": [
    "### Librerias\n",
    "\n",
    "1. pypdf\n",
    "\n",
    "- Propósito: Biblioteca para manipular archivos PDF.\n",
    "\n",
    "- Uso: Extraer texto, metadatos, dividir o combinar PDFs.\n",
    "\n",
    "2. PyMuPDF (también conocida como fitz)\n",
    "\n",
    "- Propósito: Otra biblioteca para trabajar con PDFs, más potente que PyPDF.\n",
    "\n",
    "- Uso: Extracción avanzada de texto, imágenes y metadatos de PDFs.\n",
    "\n",
    "3. python-dotenv\n",
    "\n",
    "- Propósito: Manejo de variables de entorno.\n",
    "\n",
    "- Uso: Cargar configuraciones sensibles (como claves API) desde archivos .env.\n",
    "\n",
    "4. langchain-community\n",
    "\n",
    "- Propósito: Contiene integraciones comunitarias para LangChain.\n",
    "\n",
    "- Uso: Conectores con múltiples servicios y herramientas de IA.\n",
    "\n",
    "5. langchain_openai\n",
    "\n",
    "- Propósito: Integración oficial de LangChain con los modelos de OpenAI.\n",
    "\n",
    "- Uso: Usar modelos como GPT-3.5/4, embeddings de OpenAI, etc.\n",
    "\n",
    "6. rank_bm25\n",
    "\n",
    "- Propósito: Algoritmo de ranking para recuperación de información.\n",
    "\n",
    "- Uso: Encontrar documentos relevantes basados en términos de búsqueda.\n",
    "\n",
    "7. faiss-cpu\n",
    "\n",
    "- Propósito: Biblioteca para búsqueda de similitud vectorial.\n",
    "\n",
    "- Uso: Búsqueda eficiente de vectores similares (útil para embeddings).\n",
    "\n",
    "8. deepeval\n",
    "\n",
    "- Propósito: Evaluación de respuestas de LLMs.\n",
    "\n",
    "- Uso: Medir la calidad de las respuestas generadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bb5b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pypdf==5.6.0\n",
    "!pip install PyMuPDF==1.26.1\n",
    "!pip install python-dotenv==1.1.0\n",
    "!pip install langchain-community==0.3.25\n",
    "!pip install langchain_openai==0.3.23\n",
    "!pip install rank_bm25==0.2.2\n",
    "!pip install faiss-cpu==1.11.0\n",
    "!pip install deepeval==3.1.0\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d5389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Sube un nivel en la jerarquía de directorios\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Ahora deberías poder importar\n",
    "from helper_functions import (\n",
    "    EmbeddingProvider,\n",
    "    retrieve_context_per_question,\n",
    "    replace_t_with_space,\n",
    "    get_langchain_embedding_provider,\n",
    "    show_context\n",
    ")\n",
    "from helper_functions import (EmbeddingProvider,\n",
    "                              retrieve_context_per_question,\n",
    "                              replace_t_with_space,\n",
    "                              get_langchain_embedding_provider,\n",
    "                              show_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c43e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from evaluation.evaluate_rag import evaluate_rag\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings  # Alternativa local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb4975",
   "metadata": {},
   "source": [
    "Leer documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Obtén la ruta absoluta del directorio del proyecto\n",
    "project_dir = os.path.dirname(os.path.dirname(os.path.abspath(\".\")))\n",
    "path = os.path.join(project_dir, \"RAG_Techniques\", \"data\", \"Understanding_Climate_Change.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3440724",
   "metadata": {},
   "source": [
    "Codificar documento, es decir, convertirlo en un vector de características que capturen su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa0cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pdf(\n",
    "    path: str,\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 200,\n",
    "    embedding_provider: str = \"openai\",\n",
    "    model_name: str = \"text-embedding-ada-002\"\n",
    ") -> FAISS:\n",
    "    \"\"\"\n",
    "    Codifica un documento PDF en un almacén vectorial usando embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: Ruta al archivo PDF.\n",
    "        chunk_size: Tamaño de cada fragmento de texto (en tokens).\n",
    "        chunk_overlap: Superposición entre fragmentos consecutivos.\n",
    "        embedding_provider: Proveedor de embeddings (\"openai\" o \"huggingface\").\n",
    "        model_name: Nombre del modelo a utilizar para los embeddings.\n",
    "\n",
    "    Returns:\n",
    "        FAISS: Almacén vectorial con el contenido del PDF.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: Si el archivo PDF no existe.\n",
    "        ValueError: Si los parámetros son inválidos.\n",
    "        Exception: Para otros errores durante el procesamiento.\n",
    "    \"\"\"\n",
    "    import logging\n",
    "    from pathlib import Path\n",
    "    import time\n",
    "\n",
    "    # Configuración de logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    try:\n",
    "        # Validación de parámetros\n",
    "        if not Path(path).is_file():\n",
    "            raise FileNotFoundError(f\"No se encontró el archivo: {path}\")\n",
    "        if chunk_size <= 0 or chunk_overlap < 0:\n",
    "            raise ValueError(\"chunk_size debe ser > 0 y chunk_overlap >= 0\")\n",
    "        if chunk_overlap >= chunk_size:\n",
    "            raise ValueError(\"chunk_overlap debe ser menor que chunk_size\")\n",
    "\n",
    "        logger.info(f\"Cargando documento: {path}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Cargar PDF\n",
    "        loader = PyPDFLoader(path)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        if not documents:\n",
    "            raise ValueError(\"El documento PDF está vacío o no pudo ser procesado\")\n",
    "\n",
    "        logger.info(f\"Documento cargado. Páginas: {len(documents)}\")\n",
    "        logger.info(\"Dividiendo texto en chunks...\")\n",
    "\n",
    "        # Dividir en chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        \n",
    "        if not chunks:\n",
    "            raise ValueError(\"No se pudieron generar chunks del documento\")\n",
    "\n",
    "        logger.info(f\"Generados {len(chunks)} chunks de texto\")\n",
    "\n",
    "        # Limpiar texto\n",
    "        logger.info(\"Limpiando texto...\")\n",
    "        cleaned_chunks = replace_t_with_space(chunks)\n",
    "\n",
    "        # Seleccionar proveedor de embeddings\n",
    "        logger.info(f\"Usando embeddings de {embedding_provider}...\")\n",
    "        if embedding_provider.lower() == \"huggingface\":\n",
    "            from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "            embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "        else:  # Por defecto usa OpenAI\n",
    "            from langchain_openai import OpenAIEmbeddings\n",
    "            embeddings = OpenAIEmbeddings(model=model_name)\n",
    "\n",
    "        # Crear vector store\n",
    "        logger.info(\"Creando almacén vectorial...\")\n",
    "        vectorstore = FAISS.from_documents(cleaned_chunks, embeddings)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        logger.info(f\"Proceso completado en {elapsed:.2f} segundos\")\n",
    "        \n",
    "        return vectorstore\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error al procesar el documento: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2862db",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_vector_store = encode_pdf(\n",
    "    path, \n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=200,\n",
    "    embedding_provider=\"huggingface\",\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb5e5c",
   "metadata": {},
   "source": [
    "Crear un sistema de recuperación y generación (RAG) simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los 2 fragmentos más relevantes para una consulta dada\n",
    "chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a038c",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d2cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"¿Cuál es la principal causa del cambio climático?\"\n",
    "context = retrieve_context_per_question(query, chunks_query_retriever)\n",
    "\n",
    "show_context(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1500c23",
   "metadata": {},
   "source": [
    "Evaluar resultados de recuperación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rag(chunks_query_retriever)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragNotebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
